{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "descriptive_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZAAuLb0UH58"
      },
      "source": [
        "# Preparing the enviroment and mounting data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFIKqpsjP8jD",
        "outputId": "03c3fbf1-d30a-40e3-c7ab-d0b92da68bdf"
      },
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive/\")\n",
        "#cd drive/My Drive/SFU/Project4-Spring2021\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bartpy\t\t\t\t      known_snps_fullname.txt\n",
            "cevae_cate_checkpoints_a.npy\t      known_snps.txt\n",
            "cevae_cate_checkpoints_b.npy\t      level1data_learnersout.npy\n",
            "cevae_cate_checkpoints_c.npy\t      level1data.npy\n",
            "cevae_cate_checkpoints_d.npy\t      __pycache__\n",
            "cevae_cate_checkpoints_e.npy\t      sample_data\n",
            "cevae_cate_checkpoints_f.npy\t      train.py\n",
            "cevae_cate_checkpoints.npy\t      x_clinical_names.npy\n",
            "cevae_cate_checkpoints_z.npy\t      x_clinical.npy\n",
            "cevae.py\t\t\t      x_colnames.npy\n",
            "CompBioAndSimulated_Datasets_alsoold  x_snps.npy\n",
            "CompBioAndSimulated_Datasets_old      y.npy\n",
            "eval.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERRW1W9qgUSh",
        "outputId": "acb1a59c-4943-4f40-c4ca-36b9e9f16560"
      },
      "source": [
        "!git clone https://github.com/JakeColtman/bartpy.git\n",
        "!git clone https://github.com/raquelaoki/CompBioAndSimulated_Datasets.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bartpy'...\n",
            "remote: Enumerating objects: 1971, done.\u001b[K\n",
            "remote: Total 1971 (delta 0), reused 0 (delta 0), pack-reused 1971\u001b[K\n",
            "Receiving objects: 100% (1971/1971), 11.97 MiB | 23.29 MiB/s, done.\n",
            "Resolving deltas: 100% (1329/1329), done.\n",
            "Cloning into 'CompBioAndSimulated_Datasets'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 15 (delta 5), reused 11 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (15/15), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4DyN15i-SP-"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "from scipy import sparse\n",
        "from sklearn.metrics import confusion_matrix,f1_score\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "sys.path.insert(0,'bartpy/')\n",
        "sys.path.insert(0,'CompBioAndSimulated_Datasets/')\n",
        "from bartpy.sklearnmodel import SklearnModel\n",
        "from fromBEDtoNPY import goPDX\n",
        "\n",
        "data_preprocessing = False\n",
        "run_learners = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN0J0sQlvaLt"
      },
      "source": [
        "# BCCH Data Analysis \n",
        "\n",
        "## Data \n",
        "There are two options: \n",
        "1. Pre-processing: require original files on the server and perform the pre-processing / filtering \n",
        "2. Load files saved on local machine \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzOApQiRsZw8",
        "outputId": "919441c7-ee67-41a2-ad28-9af265cbd1e3"
      },
      "source": [
        "path = '/content/'\n",
        "if data_preprocessing:  \n",
        "  print('Option 1: Starting pre-processing:')\n",
        "  data = goPDX(final=False)\n",
        "  #import data_preprossing_functions as dpf\n",
        "  #y, x_clinical, x_snps, x_colnames, x_clinical_names = dpf.run_preprocessing(path, True)\n",
        "  #x_clinical = x_clinical.astype('float64')\n",
        "  #print('Done!')\n",
        "  #print('Shapes:',len(y), sum(y), x_clinical.shape, x_snps.shape, len(x_colnames), len(x_clinical_names))\n",
        "  ##318 (318, 42) (318, 16641) 16641\n",
        "else: \n",
        "  print('Option 2: Reading files')\n",
        "  data = goPDX()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Option 2: Reading files\n",
            "Loading final form:\n",
            "Target Y:  302  items and  187  positive examples\n",
            "Clinical:  302 items and  41  columns\n",
            "SNPS:  302 items and  16195  columns\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CInR7obpXiWb"
      },
      "source": [
        "## ParKCa\n",
        "\n",
        "1. Learners: Deconfounder, BART\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-ZsJdOispRn",
        "outputId": "57ab1ca5-533c-4498-e2da-4c97ae71effc"
      },
      "source": [
        "import train as parkca\n",
        "import eval as evaluation\n",
        "import time \n",
        "learners = False\n",
        "if learners: \n",
        "  X1 = preprocessing.MinMaxScaler().fit_transform(data.x_clinical)\n",
        "  X = np.concatenate([X1,data.x_snps], axis = 1)\n",
        "\n",
        "  coef = parkca.learners(['DA','noise'],X,data.y,data.x_snps_names, colnamesZ = data.x_clinical_names) #bart is time consuming\n",
        "  #coef = parkca.learners(['CEVAE'],X,y,x_colnames, colnamesZ = x_clinical_names) #SAVED\n",
        "  z = np.load(\"cevae_cate_checkpoints_z.npy\")\n",
        "  a = np.load(\"cevae_cate_checkpoints_a.npy\")\n",
        "  b = np.load(\"cevae_cate_checkpoints_b.npy\")\n",
        "  c = np.load(\"cevae_cate_checkpoints_c.npy\")\n",
        "  d = np.load(\"cevae_cate_checkpoints_d.npy\")\n",
        "  e = np.load(\"cevae_cate_checkpoints_e.npy\")\n",
        "  f = np.load(\"cevae_cate_checkpoints_f.npy\")\n",
        "\n",
        "  print(len(z)+len(a)+len(b)+len(c)+len(d)+len(e)+len(f))\n",
        "  z = [item for sublist in z for item in sublist]\n",
        "  a = [item for sublist in a for item in sublist]\n",
        "  b = [item for sublist in b for item in sublist]\n",
        "  c = [item for sublist in c for item in sublist]\n",
        "  d = [item for sublist in d for item in sublist]\n",
        "  e = [item for sublist in e for item in sublist]\n",
        "  f = [item for sublist in f for item in sublist]\n",
        "\n",
        "  cevae_coef = np.concatenate([z,a,b,c,d,e,f], 0)\n",
        "  print(len(cevae_coef))\n",
        "  coef['CEVAE'] = cevae_coef\n",
        "  np.save('level1data',coef)\n",
        "  level1data = coef\n",
        "else: \n",
        "  level1data = np.load('level1data.npy', allow_pickle=True)\n",
        "  level1data = pd.DataFrame(level1data, columns = ['causes','DA','noise','cevae'])\n",
        "  print(level1data.head())\n",
        "\n",
        "level1data['y'] = 0\n",
        "level1data['y'] = [1 if i in data.known_snps else 0 for i in level1data['causes'].values]\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Available devices  1\n",
            "Current cuda device  0\n",
            "        causes         DA     noise      cevae\n",
            "0  1_rs3820011   0.198838   0.78991 -0.0321922\n",
            "1  1_rs6605080  -0.271758 -0.735683  -0.232704\n",
            "2   1_rs383968  0.0702615   2.11437  -0.120306\n",
            "3  1_rs2743979   -0.14591  0.930926  -0.108644\n",
            "4  1_rs4648564   0.182521 -0.192133   0.305462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h48lCt-IHtmA",
        "outputId": "c49a1301-b13f-426b-e2e8-267aa9e71f4b"
      },
      "source": [
        "level1data.set_index('causes', inplace=True, drop=True)\n",
        "level1data = parkca.data_norm(level1data)\n",
        "roc, output, y_full_prob = parkca.meta_learner(level1data.fillna(0), ['lr','nn','upu','rf'],'y')\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Meta-learner: LR\n",
            "Meta-learner: NN\n",
            "Meta-learner: UPU\n",
            "Library Missing\n",
            "Check: https://github.com/t-sakai-kure/pywsl\n",
            "Meta-learner: RF\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NWVRJ6gzcbm"
      },
      "source": [
        "output_potential_causes, output_potential_causes_signal  = [], []\n",
        "output_missing_causes, output_missing_causes_signal, output_confirmed_causes  = [], [],[]\n",
        "\n",
        "for i in range(len(output['rf'])): \n",
        "    if output['rf'][i]==1: \n",
        "        output_potential_causes.append(output.index[i])\n",
        "        output_potential_causes_signal.append(y_full_prob[i,1])\n",
        "        if output.index[i] in data.known_snps: \n",
        "            output_confirmed_causes.append(output.index[i])           \n",
        "    elif output['rf'][i]==0 and output.index[i] in data.known_snps: \n",
        "        output_missing_causes.append(output.index[i])\n",
        "        #snps.append(data1.index[i])\n",
        "        output_missing_causes_signal.append(y_full_prob[i,1])\n",
        "    else: \n",
        "      pass "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AOlASOH_-Wp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55c71628-d174-4104-9c77-1f33778ae4a7"
      },
      "source": [
        "print(\"Missing Causes:\", len(output_missing_causes))\n",
        "print(\"Confirmed Causes:\", len(output_confirmed_causes))\n",
        "print(\"New Potential Causes:\", len(output_potential_causes)-len(output_confirmed_causes))\n",
        "\n",
        "np.savetxt('output_missing_causes.txt', output_missing_causes,fmt='%s')\n",
        "np.savetxt('output_confirmed_causes.txt', output_confirmed_causes,fmt='%s')\n",
        "np.savetxt('output_potential_causes.txt', output_potential_causes,fmt='%s')\n",
        "np.savetxt('output_potential_causes_signal.txt', output_potential_causes_signal,fmt='%s')\n",
        "np.savetxt('output_missing_causes_signal.txt', output_missing_causes_signal,fmt='%s')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Missing Causes: 35\n",
            "Confirmed Causes: 32\n",
            "New Potential Causes: 127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H50i1ImRSUlS"
      },
      "source": [
        "# Predictive Models "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRb-LoM9LqgR"
      },
      "source": [
        "output_missing_causes = np.loadtxt('output_missing_causes.txt', dtype=np.str)\n",
        "output_confirmed_causes = np.loadtxt('output_confirmed_causes.txt', dtype=np.str)\n",
        "output_potential_causes = np.loadtxt('output_potential_causes.txt', dtype=np.str)\n",
        "output_potential_causes_signal= np.loadtxt('output_potential_causes_signal.txt', dtype=np.str)\n",
        "output_missing_causes_signal = np.loadtxt('output_missing_causes_signal.txt', dtype=np.str)\n",
        "\n",
        "if data_preprocessing:  \n",
        "  print('Option 1: Starting pre-processing:')\n",
        "  data = goPDX(final=False)\n",
        "  #import data_preprossing_functions as dpf\n",
        "  #y, x_clinical, x_snps, x_colnames, x_clinical_names = dpf.run_preprocessing(path, True)\n",
        "  #x_clinical = x_clinical.astype('float64')\n",
        "  #print('Done!')\n",
        "  #print('Shapes:',len(y), sum(y), x_clinical.shape, x_snps.shape, len(x_colnames), len(x_clinical_names))\n",
        "  ##318 (318, 42) (318, 16641) 16641\n",
        "else: \n",
        "  print('Option 2: Reading files')\n",
        "  data = goPDX()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MB2wXaK9681"
      },
      "source": [
        "# Option 1: using the 300\n",
        "# option 2: using the != potential (known)\n",
        "# option 3: using the confirmedis (-potential - missing)\n",
        "# option 4: using only clinical information (sex, ..., )\n",
        "# option 5: Random\n",
        "\n",
        "from random import sample\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "\n",
        "def predict_outcome(y_train, y_test, X_train, X_test, lr):\n",
        "    w = len(y_train) / y_train.sum()\n",
        "    sample_weight = np.array([w if i == 1 else 1 for i in y_train])\n",
        "    if lr: \n",
        "      model = LogisticRegression()\n",
        "      tag = 'Logistic Regression'\n",
        "    else:\n",
        "      model = RandomForestClassifier(max_depth=6, random_state=0)\n",
        "      tag = 'Random Forest'\n",
        "    model.fit(X_train, y_train, sample_weight=sample_weight)\n",
        "\n",
        "    y_train_p = model.predict(X_train)\n",
        "    y_test_p = model.predict(X_test)\n",
        "\n",
        "    f1_train = f1_score(y_train, y_train_p)\n",
        "    f1_test = f1_score(y_test, y_test_p)\n",
        "\n",
        "    p_train = precision_score(y_train, y_train_p)\n",
        "    p_test = precision_score(y_train, y_train_p)\n",
        "\n",
        "    r_train = recall_score(y_train, y_train_p)\n",
        "    r_test = recall_score(y_train, y_train_p)\n",
        "\n",
        "\n",
        "    return tag, f1_train, p_train, r_train, f1_test, p_test, r_test \n",
        "\n",
        "def predictive_models_comp(option, data, filter, typemodel = False):\n",
        "    \n",
        "    # print(option)\n",
        "    if option == 1:\n",
        "      tag = 'All Potential SNPs + Clinical'\n",
        "    elif option == 2:      \n",
        "      tag = 'Known SNPs + Clinical'\n",
        "    elif option == 3:      \n",
        "      tag = 'Confirmed SNPs + Clinical'\n",
        "    elif option == 4:      \n",
        "      tag = 'Only Clinical'\n",
        "    else:\n",
        "      tag = 'Random SNPs + Clinical'\n",
        "\n",
        "    remove = []\n",
        "    for i in range(len(data.x_snps_names)):\n",
        "        if data.x_snps_names[i] not in filter:\n",
        "            remove.append(i)\n",
        "\n",
        "\n",
        "    X = np.delete(data.x_snps, remove, axis=1)\n",
        "    colX = np.delete(data.x_snps_names, remove, axis=0)\n",
        "\n",
        "    y = data.y\n",
        "    scaler = MinMaxScaler()\n",
        "    Z = scaler.fit_transform(data.x_clinical)\n",
        "\n",
        "    if option == 4:\n",
        "        X = Z\n",
        "    else:\n",
        "        X = np.concatenate([Z, X], axis=1)\n",
        "\n",
        "    rep = 30\n",
        "    f1_train, f1_test = np.zeros(rep), np.zeros(rep)\n",
        "    for seed in range(rep):\n",
        "      y_train, y_test, X_train, X_test = train_test_split(y, X, test_size=0.3, random_state=seed) #8\n",
        "      model, f1_train[seed], p_train, r_train, f1_test[seed], p_test, r_test = predict_outcome(y_train, y_test, X_train, X_test,typemodel)\n",
        "      \n",
        "    roc = {'type': tag,'model':model, 'f1_train':f1_train.mean(), 'f1_train_sd':np.std(f1_train), \n",
        "           'f1_test': f1_test.mean(), 'f1_test_sd':np.std(f1_test)}\n",
        "    #roc = {'type': tag,'model':model, 'f1_train':f1_train, 'p_train':p_train, 'r_train':r_train,\n",
        "    #       'f1_test': f1_test, 'p_test':p_test, \"r_test\":r_test}\n",
        "    return roc\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAEVc-cA4n9G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "04b101d0-d94c-42c7-9c28-934fa0c6ef72"
      },
      "source": [
        "roc_table = pd.DataFrame(columns=['type','model', 'f1_train', 'f1_train_sd','f1_test','f1_test_sd'])\n",
        "roc_table = roc_table.append(predictive_models_comp(1, data,output_potential_causes ), ignore_index=True)\n",
        "roc_table = roc_table.append(predictive_models_comp(1, data,output_potential_causes,True ), ignore_index=True)\n",
        "roc_table = roc_table.append(predictive_models_comp(2, data, data.known_snps), ignore_index=True)\n",
        "roc_table = roc_table.append(predictive_models_comp(2, data, data.known_snps,True), ignore_index=True)\n",
        "roc_table = roc_table.append(predictive_models_comp(3, data, output_confirmed_causes), ignore_index=True)\n",
        "roc_table = roc_table.append(predictive_models_comp(3, data, output_confirmed_causes,True), ignore_index=True)\n",
        "roc_table = roc_table.append(predictive_models_comp(4, data, [] ), ignore_index=True)\n",
        "roc_table = roc_table.append(predictive_models_comp(4, data, [] ,True), ignore_index=True)\n",
        "roc_table = roc_table.append(predictive_models_comp(5, data,sample(list(data.x_snps_names),40) ), ignore_index=True)\n",
        "roc_table = roc_table.append(predictive_models_comp(5, data,sample(list(data.x_snps_names),40),True ), ignore_index=True)\n",
        "\n",
        "roc_table"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>model</th>\n",
              "      <th>f1_train</th>\n",
              "      <th>f1_train_sd</th>\n",
              "      <th>f1_test</th>\n",
              "      <th>f1_test_sd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>All Potential SNPs</td>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.954704</td>\n",
              "      <td>0.011717</td>\n",
              "      <td>0.786759</td>\n",
              "      <td>0.036269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>All Potential SNPs</td>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.971956</td>\n",
              "      <td>0.008669</td>\n",
              "      <td>0.711725</td>\n",
              "      <td>0.039134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Known SNPs</td>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.955176</td>\n",
              "      <td>0.012017</td>\n",
              "      <td>0.792458</td>\n",
              "      <td>0.033726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Known SNPs</td>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.889759</td>\n",
              "      <td>0.012123</td>\n",
              "      <td>0.786599</td>\n",
              "      <td>0.034322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Confirmed SNPs</td>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.956204</td>\n",
              "      <td>0.009467</td>\n",
              "      <td>0.789531</td>\n",
              "      <td>0.034293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Confirmed SNPs</td>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.864247</td>\n",
              "      <td>0.013196</td>\n",
              "      <td>0.784731</td>\n",
              "      <td>0.037986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Only Clinical</td>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.967209</td>\n",
              "      <td>0.008133</td>\n",
              "      <td>0.792456</td>\n",
              "      <td>0.035498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Only Clinical</td>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.842284</td>\n",
              "      <td>0.016026</td>\n",
              "      <td>0.797318</td>\n",
              "      <td>0.031750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>random</td>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.964118</td>\n",
              "      <td>0.007630</td>\n",
              "      <td>0.787228</td>\n",
              "      <td>0.035105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>random</td>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.881759</td>\n",
              "      <td>0.015616</td>\n",
              "      <td>0.765805</td>\n",
              "      <td>0.038039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 type                model  ...   f1_test  f1_test_sd\n",
              "0  All Potential SNPs        Random Forest  ...  0.786759    0.036269\n",
              "1  All Potential SNPs  Logistic Regression  ...  0.711725    0.039134\n",
              "2          Known SNPs        Random Forest  ...  0.792458    0.033726\n",
              "3          Known SNPs  Logistic Regression  ...  0.786599    0.034322\n",
              "4      Confirmed SNPs        Random Forest  ...  0.789531    0.034293\n",
              "5      Confirmed SNPs  Logistic Regression  ...  0.784731    0.037986\n",
              "6       Only Clinical        Random Forest  ...  0.792456    0.035498\n",
              "7       Only Clinical  Logistic Regression  ...  0.797318    0.031750\n",
              "8              random        Random Forest  ...  0.787228    0.035105\n",
              "9              random  Logistic Regression  ...  0.765805    0.038039\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hWg1r2_-coP"
      },
      "source": [
        "# ADD ONLY SNPS \n",
        "# ADD ONLY RANDOM SNPs \n",
        "# EXTRACT MOST IMPORTANT CLINICAL FEATURES \n",
        "# Model with most important clinical variables - removed correlated variables"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D3eXyEJv1su",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72140a95-4c06-4e3a-dc6e-e3fd760dfea8"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wPRf9x35DEA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hJCK3hk-G6W"
      },
      "source": [
        "TODO: make the correlation plot with all snps and clinical data. \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGm7h3l--R1D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEX5_Saew631"
      },
      "source": [
        "samples = np.load('snpsback_variants.npy')\n",
        "np.savetxt('snpsback_variants.txt', samples,'%s')"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpcqFPHwoWQR",
        "outputId": "8cf4132a-153c-4f51-c565-2da3e5e0a6fe"
      },
      "source": [
        "print(samples[23399], samples[90349])\n",
        "print(samples[23399+1], samples[90349+1])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3_rs7650615 15_rs150980610\n",
            "3_rs138342348 15_rs78666809\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}