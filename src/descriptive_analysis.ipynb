{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "descriptive_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZAAuLb0UH58"
      },
      "source": [
        "# Preparing the enviroment and mounting data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFIKqpsjP8jD",
        "outputId": "b1b23335-17f8-4975-cafa-44c1e5f67db6"
      },
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive/\")\n",
        "#cd drive/My Drive/SFU/Project4-Spring2021\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bartpy\t\t\t known_snps.txt  train.py\t       x_colnames.npy\n",
            "eval.py\t\t\t __pycache__\t x_clinical_names.npy  x_snps.npy\n",
            "known_snps_fullname.txt  sample_data\t x_clinical.npy        y.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERRW1W9qgUSh",
        "outputId": "dc872bcb-8695-47b4-87de-f47f60ca14e9"
      },
      "source": [
        "!git clone https://github.com/JakeColtman/bartpy.git\n",
        "#can i just clone parkca? check the differences between my train and the one on the package"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'bartpy' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4DyN15i-SP-"
      },
      "source": [
        "# reading snps file\n",
        "#libraries\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "from scipy import sparse\n",
        "from sklearn.metrics import confusion_matrix,f1_score\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "sys.path.insert(0,'bartpy/')\n",
        "from bartpy.sklearnmodel import SklearnModel\n",
        "\n",
        "data_preprocessing = False\n",
        "run_learners = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN0J0sQlvaLt"
      },
      "source": [
        "# BCCH Data Analysis \n",
        "\n",
        "## Data \n",
        "There are two options: \n",
        "1. Pre-processing: require original files on the server and perform the pre-processing / filtering \n",
        "2. Load files saved on local machine \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzOApQiRsZw8",
        "outputId": "deba66cb-3fb4-4167-9e0e-2be6164e882b"
      },
      "source": [
        "path = '/content/'\n",
        "if data_preprocessing:  \n",
        "  print('Option 1: Starting pre-processing:')\n",
        "  import data_preprossing_functions as dpf\n",
        "  y, x_clinical, x_snps, x_colnames, x_clinical_names = dpf.run_preprocessing(path, True)\n",
        "  x_clinical = x_clinical.astype('float64')\n",
        "  print('Done!')\n",
        "  print('Shapes:',len(y), sum(y), x_clinical.shape, x_snps.shape, len(x_colnames), len(x_clinical_names))\n",
        "  #318 (318, 42) (318, 16641) 16641\n",
        "else: \n",
        "  print('Option 2: Reading files')\n",
        "  y =  np.load('y.npy')\n",
        "  x_clinical = np.load('x_clinical.npy',allow_pickle =True)\n",
        "  x_clinical = x_clinical.astype('float64')\n",
        "  x_clinical_names = np.load('x_clinical_names.npy',allow_pickle =True)\n",
        "  x_snps = np.load('x_snps.npy',allow_pickle =True)\n",
        "  x_colnames  = np.load('x_colnames.npy',allow_pickle =True)\n",
        "  print('Done!')\n",
        "  print('Shapes:',len(y), sum(y), x_clinical.shape, x_snps.shape, len(x_colnames), len(x_clinical_names))\n",
        " "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Option 2: Reading files\n",
            "Done!\n",
            "Shapes: 302 187 (302, 41) (302, 16195) 16195 41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CInR7obpXiWb"
      },
      "source": [
        "## ParKCa\n",
        "\n",
        "1. Learners: Deconfounder, BART\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-ZsJdOispRn",
        "outputId": "05a3e080-4228-4f67-d685-2dd08e83d0c4"
      },
      "source": [
        "import train as parkca\n",
        "import eval as evaluation\n",
        "\n",
        "#if run_learners:\n",
        "#  level1data = parkca.learners_bcch(path_output = path, learners = ['DA'], X = x_snps, y = y, \n",
        "#                                    colnamesX = x_colnames,causes = 'snps', Z = x_clinical, colnamesZ = x_clinical_names)\n",
        "\n",
        "X = np.concatenate([x_clinical,x_snps], axis = 1)\n",
        "print(X.shape)\n",
        "\n",
        "X = preprocessing.StandardScaler().fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "(302, 16236)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pstKirKH6okY",
        "outputId": "cb221331-dad0-48ac-b59b-a2c64f378e68"
      },
      "source": [
        "#model_da = parkca.learner_deconfounder_algorithm(X_train, X_test, y_train, y_test, 10)\n",
        "#model_bart = parkca.learner_BART(X_train, X_test, y_train, y_test)\n",
        "#coef = parkca.learners(['DA','BART','noise'],X,y,x_colnames) #bart is time consuming, bad for testing\n",
        "level1data = parkca.learners(['DA','noise'],X,y,x_colnames)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Learner: DA\n",
            "... There are  1  versions of DA\n",
            "...... Version 1/ 1\n",
            "Running DA\n",
            "... Done Holdout\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8bmWmGeb02l"
      },
      "source": [
        "#\n",
        "#bart.fit()\n",
        "#coef, coef_c, roc  = model_da.fit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4npHHgvhaK8"
      },
      "source": [
        "level1data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrPjsO5Is4Vi"
      },
      "source": [
        "level1data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om2jrvXYucAM"
      },
      "source": [
        "ks = pd.read_csv(path+'known_snps_fullname.txt', header = None)[0].values\n",
        "level1data['y'] = 0\n",
        "level1data['y'] = [1 if i in ks else 0 for i in level1data['causes'].values]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcHKS5z2wk1b"
      },
      "source": [
        "qav, q_ = evaluation.diversity(['DA_15','noise'], level1data, 'y')\n",
        "print('Diversity (Best when <= 0): ', qav)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACV8UeeuvlgF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bShekq_vgpyo"
      },
      "source": [
        "level1data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IR34_mBugpW"
      },
      "source": [
        "level1data.set_index('causes', inplace = True, drop = True) \n",
        "level1data = parkca.data_norm(level1data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHaTG8vfzcC9"
      },
      "source": [
        "roc, output = parkca.meta_learner(level1data, ['rf','lr','nn','upu'],'y')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NWVRJ6gzcbm"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AOlASOH_-Wp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNQRUjIyA3EE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}