{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "descriptive_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZAAuLb0UH58"
      },
      "source": [
        "# Preparing the enviroment and mounting data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFIKqpsjP8jD",
        "outputId": "8adc043a-bdf3-4970-e81b-b7fe1902f6ea"
      },
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive/\")\n",
        "#cd drive/My Drive/SFU/Project4-Spring2021\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_preprossing_functions.py  known_snps.txt  x_clinical_names.npy  x_snps.npy\n",
            "eval.py\t\t\t       sample_data     x_clinical.npy\t     y.npy\n",
            "known_snps_fullname.txt        train.py        x_colnames.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERRW1W9qgUSh",
        "outputId": "013a0a8f-4a51-48b6-c297-635af7bf6f20"
      },
      "source": [
        "!git clone https://github.com/JakeColtman/bartpy.git\n",
        "#can i just clone parkca? check the differences between my train and the one on the package"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bartpy'...\n",
            "remote: Enumerating objects: 1971, done.\u001b[K\n",
            "remote: Total 1971 (delta 0), reused 0 (delta 0), pack-reused 1971\u001b[K\n",
            "Receiving objects: 100% (1971/1971), 11.97 MiB | 10.36 MiB/s, done.\n",
            "Resolving deltas: 100% (1329/1329), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4DyN15i-SP-"
      },
      "source": [
        "# reading snps file\n",
        "#libraries\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "from scipy import sparse\n",
        "from sklearn.metrics import confusion_matrix,f1_score\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'bartpy/')\n",
        "from bartpy.sklearnmodel import SklearnModel\n",
        "\n",
        "preprocessing = False\n",
        "run_learners = False"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN0J0sQlvaLt"
      },
      "source": [
        "# BCCH Data Analysis \n",
        "\n",
        "## Data \n",
        "There are two options: \n",
        "1. Pre-processing: require original files on the server and perform the pre-processing / filtering \n",
        "2. Load files saved on local machine \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzOApQiRsZw8",
        "outputId": "bc854e81-2233-4705-aca1-48decb8d6056"
      },
      "source": [
        "path = '/content/'\n",
        "if preprocessing:  \n",
        "  print('Option 1: Starting pre-processing:')\n",
        "  import data_preprossing_functions as dpf\n",
        "  y, x_clinical, x_snps, x_colnames, x_clinical_names = dpf.run_preprocessing(path, True)\n",
        "  x_clinical = x_clinical.astype('float64')\n",
        "  print('Done!')\n",
        "  print('Shapes:',len(y), sum(y), x_clinical.shape, x_snps.shape, len(x_colnames), len(x_clinical_names))\n",
        "  #318 (318, 42) (318, 16641) 16641\n",
        "else: \n",
        "  print('Option 2: Reading files')\n",
        "  y =  np.load('y.npy')\n",
        "  x_clinical = np.load('x_clinical.npy',allow_pickle =True)\n",
        "  x_clinical = x_clinical.astype('float64')\n",
        "  x_clinical_names = np.load('x_clinical_names.npy',allow_pickle =True)\n",
        "  x_snps = np.load('x_snps.npy',allow_pickle =True)\n",
        "  x_colnames  = np.load('x_colnames.npy',allow_pickle =True)\n",
        "  print('Done!')\n",
        "  print('Shapes:',len(y), sum(y), x_clinical.shape, x_snps.shape, len(x_colnames), len(x_clinical_names))\n",
        " "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Option 2: Reading files\n",
            "Done!\n",
            "Shapes: 302 187 (302, 41) (302, 16195) 16195 41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CInR7obpXiWb"
      },
      "source": [
        "## ParKCa\n",
        "\n",
        "1. Learners: Deconfounder, BART, CEVAE\n",
        "\n",
        "BART OR CEVAE CODE? \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-ZsJdOispRn",
        "outputId": "7268ebf5-a878-4999-b79c-4c71230f0934"
      },
      "source": [
        "if run_learners:\n",
        "  import train as parkca\n",
        "  level1data = parkca.learners_bcch(path_output = path, DA = True, BART = True, X = x_snps, y = y, \n",
        "                                    colnamesX = x_colnames,causes = 'snps', Z = x_clinical, colnamesZ = x_clinical_names)\n",
        "\n",
        "X = np.concatenate([x_clinical,x_snps], axis = 1)\n",
        "print(X.shape)\n",
        "\n",
        "X = preprocessing.StandardScaler().fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(302, 16236)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrPjsO5Is4Vi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d62cf9d-c64f-40ff-f1c3-1c090d557abb"
      },
      "source": [
        "print('...Learner: BART')\n",
        "model = SklearnModel(n_trees = 50,n_burn = 50, n_chains=1, n_jobs=1 ) # Use default parameters\n",
        "model.fit(X_train, y_train) # Fit the model\n",
        "print('......making predictions')\n",
        "y_train_pred = model.predict(X_train) # [:,0:1000] Make predictions on the train set\n",
        "y_test_pred = model.predict(X_test) # [:,0:1000] Make predictions on the train set\n",
        "\n",
        "def Find_Optimal_Cutoff(target, predicted):\n",
        "    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
        "    Parameters\n",
        "    ----------\n",
        "    target : Matrix with dependent or target data, where rows are observations\n",
        "\n",
        "    predicted : Matrix with predicted data, where rows are observations\n",
        "\n",
        "    Returns\n",
        "    -------     \n",
        "    list type, with optimal cutoff value\n",
        "    https://stackoverflow.com/questions/28719067/roc-curve-and-cut-off-point-python\n",
        "    \"\"\"\n",
        "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
        "    i = np.arange(len(tpr)) \n",
        "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
        "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
        "\n",
        "    return list(roc_t['threshold']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "...Learner: BART\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting burn\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  2%|â–         | 1/50 [00:07<05:48,  7.10s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om2jrvXYucAM"
      },
      "source": [
        "thhold = Find_Optimal_Cutoff(y_train,y_train_pred)\n",
        "y_train_pred01 = [0 if item < thhold else 1 for item in y_train_pred]\n",
        "y_test_pred01 = [0 if item < thhold else 1 for item in y_test_pred]\n",
        "print('\\n...Training set: F1 - ',f1_score(y_train,y_train_pred01))\n",
        "print('...... confusion matrix: ',confusion_matrix(y_train,y_train_pred01).ravel())\n",
        "\n",
        "print('\\n...Testing set: F1 - ',f1_score(y_test,y_test_pred01))\n",
        "print('...... confusion matrix: ',confusion_matrix(y_test,y_test_pred01).ravel())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcHKS5z2wk1b"
      },
      "source": [
        "#very bad on testing "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}